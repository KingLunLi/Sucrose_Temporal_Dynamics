{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sy\n",
    "import os\n",
    "from scipy import stats\n",
    "from more_itertools import numeric_range\n",
    "import math\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to align the start time of the behavioral (lever press timing) and miniscope (neural activities) recordings, we initiate the miniscope recording prior to the behavioral training and subtract the time difference.\n",
    "\n",
    "More specifically, we determine the time difference when the behavior session begins and when the miniscope begins recording. Then, we subtract the timing in the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the time in sec to be deleted from analysis.  This is the time difference between the onset of the miniscope and behavioral recordings.\n",
    "bf_time=[4.3]\n",
    "t=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the directory.  Please specify the directory accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = 'C:/Users/AK_ROG/GitGithub/Research_Projects/sucrose-neuro/Standardizing'\n",
    "\n",
    "files = \"example_neural_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delta f over f is one type of standardization \n",
    "\n",
    "The following code outputs a csv file containing the Delta F/F data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3\n"
     ]
    }
   ],
   "source": [
    "### Delta f over f\n",
    "#     for files in os.listdir(sample_dir):\n",
    "print(bf_time[t])\n",
    "\n",
    "raw_data = pd.read_csv(files)\n",
    "name = files[:-4]\n",
    "before_time = bf_time[t]\n",
    "data = raw_data.copy()\n",
    "data = data - min(data.iloc[:,range(1,len(data.columns))].min())\n",
    "data['ceil_time'] = (data['Time(ms)']/100).apply(np.ceil).astype(int)*100\n",
    "data = data.groupby(['ceil_time']).mean()\n",
    "data = data.reset_index()\n",
    "data['Time(ms)'] = data['ceil_time']\n",
    "data = data.drop('ceil_time', axis=1)\n",
    "data = data.rename(columns={'Time(ms)':'Time(s)'})\n",
    "data['Time(s)'] = round(data['Time(s)']/1000,1)\n",
    "delete_indx = data[data['Time(s)'] <= before_time].index\n",
    "#print(delete_indx)\n",
    "data.drop(delete_indx, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data['Time(s)'] = data['Time(s)'] - before_time\n",
    "#data.head()\n",
    "cols = data.columns\n",
    "z_data = pd.DataFrame(columns=cols)\n",
    "z_data['Time(s)'] = data['Time(s)']\n",
    "for xc in range(1,len(cols)):\n",
    "    for ran in range(0,math.ceil(len(data)/3000)):\n",
    "        if (ran+1)*3000<len(data):\n",
    "            baseline = data.iloc[range(ran*3000,(ran+1)*3000),xc].mean()\n",
    "            z_data.iloc[range(ran*3000,(ran+1)*3000),xc] = (data.iloc[range(ran*3000,(ran+1)*3000),xc] - baseline)/baseline\n",
    "        else:\n",
    "            baseline = data.iloc[range(len(data)-3000,len(data)),xc].mean()\n",
    "            z_data.iloc[range(ran*3000,len(data)),xc] = (data.iloc[range(ran*3000,len(data)),xc] - baseline)/baseline\n",
    "\n",
    "z_data[\"Time(s)\"]=round(z_data[\"Time(s)\"],1)\n",
    "z_data.to_csv(sample_dir + name +'_deltaF_over_F.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-score is another type of standardization \n",
    "The following code outputs a csv file containing the z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_neural_data.csv\n",
      "4.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
      "<ipython-input-5-35cab666695d>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n"
     ]
    }
   ],
   "source": [
    "print(files)\n",
    "print(bf_time[t])\n",
    "\n",
    "raw_data = pd.read_csv(files)\n",
    "name = files[:-4]\n",
    "before_time = bf_time[t]\n",
    "data = raw_data.copy()\n",
    "data['ceil_time'] = (data['Time(ms)']/100).apply(np.ceil).astype(int)*100\n",
    "data = data.groupby(['ceil_time']).mean()\n",
    "data = data.reset_index()\n",
    "data['Time(ms)'] = data['ceil_time']\n",
    "data = data.drop('ceil_time', axis=1)\n",
    "data = data.rename(columns={'Time(ms)':'Time(s)'})\n",
    "data['Time(s)'] = round(data['Time(s)']/1000,1)\n",
    "delete_indx = data[data['Time(s)'] <= before_time].index\n",
    "#print(delete_indx)\n",
    "data.drop(delete_indx, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data['Time(s)'] = data['Time(s)'] - before_time\n",
    "#data.head()\n",
    "cols = raw_data.columns\n",
    "cols = cols[1:]\n",
    "z_data = pd.DataFrame()\n",
    "for col in cols:\n",
    "    col_zscore = col + '_zscore'\n",
    "    z_data['Time(s)'] = data['Time(s)']\n",
    "    z_data[col] = (data[col] - data[col].mean())/data[col].std(ddof=0)\n",
    "\n",
    "z_data[\"Time(s)\"]=round(z_data[\"Time(s)\"],1)\n",
    "#z_data.tail()\n",
    "z_data.to_csv(sample_dir + name +'_standardized.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
