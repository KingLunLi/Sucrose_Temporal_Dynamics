{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "import IPython.display as display\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from typing import Union\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.metrics.pairwise import chi2_kernel\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.animation as animation\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from multiprocess import Pool # https://pypi.org/project/multiprocess/\n",
    "import time_constants as tc\n",
    "from helper_functions_dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Lever Times\n",
    "tc.updateTimes(-10, 10)\n",
    "\n",
    "TIME_LOWER = tc.TIME[\"LOWER\"]\n",
    "TIME_UPPER = tc.TIME[\"UPPER\"]\n",
    "TOT_TIME = tc.TIME[\"TOTAL\"]\n",
    "\n",
    "# os.path.join() will be useful for switching between mac, windows, linux \n",
    "\n",
    "pal = sns.color_palette('husl', 9)\n",
    "TIME_LOWER, TIME_UPPER, TOT_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mTypes = {'WT':['152', '153', '174', '175', '177', '180', '181'], \n",
    "          'D1':['D1#14', 'D1#15', 'D1#21', 'D1#7', 'D1#33'],\n",
    "          'D2':['D2#13', 'D2#24', 'D2#36', 'D2#23', 'D2#38', 'D2#52']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that this code is in the same directory as each folder, which is organized as:\n",
    "'''\n",
    "Sucrose_data_and_code(folder)\n",
    "|- This code\n",
    "|- Rodent(folder)\n",
    "   |- rodent_day1_...\n",
    "   |- rodent_day-whatever...csv etc.\n",
    "|- Another_Rodent(folder)\n",
    "   |- blah blah...csv\n",
    "'''\n",
    "days = ['Day11']\n",
    "USE_CUT = False\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data objects\n",
    "mTypeDats = dict()\n",
    "for key in mTypes:\n",
    "    print(key)\n",
    "    rodents = mTypes[key]\n",
    "    mTypeDats[key] = []\n",
    "    for d in days:\n",
    "        data = dict()\n",
    "        for rodent in rodents:\n",
    "            print(rodent, d)\n",
    "            dat = DataLoader(\"data\\\\\" + rodent, rodent, d, use_manifold_transformed=True, use_cut=USE_CUT)\n",
    "            data[rodent] = dat\n",
    "        mTypeDats[key].append((d, data))\n",
    "mTypeDats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAC_PART = 5\n",
    "colTimes = []\n",
    "addr = float(TIME_LOWER)\n",
    "while addr <= TIME_UPPER:\n",
    "    colTimes.append(addr)\n",
    "    addr += 1*FRAC_PART/10\n",
    "    addr = np.round(addr, 1)\n",
    "colNames = [\"[{t1},{t2})\".format(t1 = colTimes[i], t2 = colTimes[i+1]) for i in range(len(colTimes) - 1)]\n",
    "print(colNames)\n",
    "my_index = pd.MultiIndex(levels=[[],[],[],[],[]], codes=[[],[],[],[],[]], names=[u'Type', u'Day', u'Rodent', u'iter', u'nALP'])\n",
    "df_results = pd.DataFrame([], columns=colNames, index=my_index, dtype=float)\n",
    "df_results_shuff = pd.DataFrame([], columns=colNames, index=my_index, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelRun(inp):\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.decomposition import FactorAnalysis\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import time_constants as tc\n",
    "    from sklearn.preprocessing import FunctionTransformer\n",
    "    from helper_functions_dataloader import expandTimeWindow\n",
    "    \n",
    "    iter,mTypeDats,TOT_TIME,TIME_LOWER,TIME_UPPER,FRAC_PART,IS_PCA,colNames,my_index = inp\n",
    "    df_results = pd.DataFrame([], columns=colNames, index=my_index, dtype=float)\n",
    "    df_results_shuff = pd.DataFrame([], columns=colNames, index=my_index, dtype=float)\n",
    "    mTypeDFs = dict()\n",
    "    aggFunc = lambda x,y: np.concatenate((np.nanmean(x, axis=0), np.nanmean(y, axis=0)), axis=0)\n",
    "    tc.updateTimes(TIME_LOWER, TIME_UPPER)\n",
    "\n",
    "    for key in mTypeDats:\n",
    "        rodents = mTypeDats[key]\n",
    "        mTypeDFs[key] = []\n",
    "        for day, mice in rodents:\n",
    "            for dlKey in mice:\n",
    "                print(key, day, dlKey)\n",
    "                # Load in data from dataloader\n",
    "                loader = mice[dlKey]\n",
    "                if loader.empty or len(loader.times_ALP) == 0:\n",
    "                    continue\n",
    "                LP1 = expandTimeWindow(loader.df_times, loader.times_ALP, time_grouped=True)\n",
    "                LP2 = expandTimeWindow(loader.df_times, loader.times_ALP, shuffle=True, time_grouped=True)\n",
    "                LP3 = expandTimeWindow(loader.df_times, loader.times_ALP, shuffle=True, time_grouped=True)\n",
    "                LP4 = expandTimeWindow(loader.df_times, loader.times_ALP, shuffle=True, time_grouped=True)\n",
    "\n",
    "                # Set up data split\n",
    "                numModels = TOT_TIME//FRAC_PART if FRAC_PART != 1 else TOT_TIME-1\n",
    "                skf = ShuffleSplit(n_splits=1, test_size=.4)\n",
    "                agg = {i:[] for i in range(numModels)}\n",
    "                aggShuff = {i:[] for i in range(numModels)}\n",
    "\n",
    "                for train_index, test_index in skf.split(loader.times_ALP):\n",
    "                    # Split data points\n",
    "                    train_set_1, train_set_2 = LP1[train_index], LP2[train_index]\n",
    "                    test_set_1, test_set_2 = LP1[test_index], LP2[test_index]\n",
    "\n",
    "                    train_set_3, train_set_4 = LP3[train_index], LP4[train_index]\n",
    "                    test_set_3, test_set_4 = LP3[test_index], LP4[test_index]\n",
    "\n",
    "                    # Set up dim reduction pipeline\n",
    "                    pipe = Pipeline([('scaler', StandardScaler()),('pca', PCA(n_components=3))])\n",
    "                    pca_fit_inp = aggFunc(train_set_1,train_set_2)\n",
    "                    pipe.fit(pca_fit_inp)\n",
    "\n",
    "                    pipe_shuff = Pipeline([('scaler', StandardScaler()),('pca', PCA(n_components=3))])\n",
    "                    pca_fit_inp_shuff = aggFunc(train_set_3,train_set_4)\n",
    "                    pipe_shuff.fit(pca_fit_inp_shuff)\n",
    "\n",
    "                    for timeRange in range(numModels):\n",
    "                        # Set up time ranges and helper functions\n",
    "                        lTrain, uTrain = timeRange*FRAC_PART, (timeRange+1)*FRAC_PART\n",
    "                        remove_nan = lambda x: list(filter(lambda y: not np.any(np.isnan(y)), x))\n",
    "                        reshape = lambda x: x.reshape(x.shape[0]*x.shape[1], x.shape[2])\n",
    "                        def res_conc_trans(x,y,pipe):\n",
    "                            l_arr = remove_nan(reshape(x[:,lTrain:uTrain,:]))\n",
    "                            r_arr = remove_nan(reshape(y[:,lTrain:uTrain,:]))\n",
    "                            res_conc = np.concatenate((l_arr,r_arr), axis=0)\n",
    "                            if np.any(np.isnan(res_conc)):\n",
    "                                raise Exception(\"bruh\")\n",
    "                            return pipe.transform(res_conc), len(l_arr), len(r_arr)\n",
    "                            \n",
    "                        # Prep test data\n",
    "                        train_dat, train_ll, train_rl = res_conc_trans(train_set_1, train_set_2, pipe)\n",
    "                        test_dat, test_ll, test_rl = res_conc_trans(test_set_1, test_set_2, pipe)\n",
    "                        train_dat_shuff, train_ll_shuff, train_rl_shuff = res_conc_trans(train_set_3, train_set_4, pipe_shuff)\n",
    "                        test_dat_shuff, test_ll_shuff, test_rl_shuff = res_conc_trans(test_set_3, test_set_4, pipe_shuff)\n",
    "                    \n",
    "                        train_labels = [0]*train_ll + [1]*train_rl\n",
    "                        test_labels = [0]*test_ll + [1]*test_rl\n",
    "                        train_labels_shuff = [0]*train_ll_shuff + [1]*train_rl_shuff\n",
    "                        test_labels_shuff = [0]*test_ll_shuff + [1]*test_rl_shuff\n",
    "\n",
    "                        # SVM and scoring\n",
    "                        svm = Pipeline([('scaler', StandardScaler()),('svm', LinearSVC(C=0.9, max_iter=10000, dual=False))])\n",
    "                        svm.fit(train_dat, train_labels)                                \n",
    "                        pred_labels = svm.predict(test_dat)\n",
    "                        accuracy = balanced_accuracy_score(test_labels, pred_labels, sample_weight=[test_rl/(test_ll + test_rl)]*test_ll + [test_ll/(test_ll + test_rl)]*test_rl)\n",
    "                        agg[timeRange].append(accuracy)\n",
    "\n",
    "                        # SVM and scoring of shuffle\n",
    "                        svm_shuff = Pipeline([('scaler', StandardScaler()),('svm', LinearSVC(C=0.9, max_iter=10000, dual=False))])\n",
    "                        svm_shuff.fit(train_dat_shuff, train_labels_shuff)                                \n",
    "                        pred_labels = svm_shuff.predict(test_dat_shuff)\n",
    "                        accuracy = balanced_accuracy_score(test_labels_shuff, pred_labels, sample_weight=[test_rl_shuff/(test_ll_shuff + test_rl_shuff)]*test_ll_shuff + [test_ll_shuff/(test_ll_shuff + test_rl_shuff)]*test_rl_shuff)\n",
    "                        aggShuff[timeRange].append(accuracy)\n",
    "                \n",
    "                df_results.loc[(key, day, dlKey, iter, len(loader.times_ALP)),:] = [np.mean(agg[i]) for i in agg]\n",
    "                df_results_shuff.loc[(key, day, dlKey, iter, len(loader.times_ALP)),:] = [np.mean(aggShuff[i]) for i in aggShuff]\n",
    "    return df_results,df_results_shuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ ==  '__main__':\n",
    "    num_iters = 100\n",
    "    num_processors = 11\n",
    "    p=Pool(processes = num_processors)\n",
    "    arr = p.map(parallelRun,[(i,mTypeDats,TOT_TIME,TIME_LOWER,TIME_UPPER,FRAC_PART,IS_PCA,colNames,my_index) for i in range(0,num_iters)])\n",
    "    results_arr, shuff_arr = [x for (x,_) in arr],[y for (_,y) in arr]\n",
    "    df_results = pd.concat(results_arr)\n",
    "    df_results_shuff = pd.concat(shuff_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in mTypeDats:\n",
    "    rodents = mTypeDats[key]\n",
    "    for day, mice in rodents:\n",
    "        plt.plot(df_results.loc[key, day, :].mean(), label=\"ALP v Shuff\")\n",
    "        plt.plot(df_results_shuff.loc[key, day, :].mean(), label=\"Shuff v Shuff\")\n",
    "        plt.title(key + \" \" + day)      \n",
    "        plt.ylim((0.375, 0.775))\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.legend() \n",
    "        plt.show()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('[3PC]sucrose-alp-shuff.csv')\n",
    "df_results_shuff.to_csv('[3PC]sucrose-shuff-shuff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_index = pd.MultiIndex(levels=[[],[],[]], codes=[[],[],[]], names=[u'Type', u'Day', u'Rodent'])\n",
    "df_result_means = pd.DataFrame([], columns=colNames, index=my_index, dtype=float)\n",
    "df_result_sems = pd.DataFrame([], columns=colNames, index=my_index, dtype=float)\n",
    "df_result_shuff_means = pd.DataFrame([], columns=colNames, index=my_index, dtype=float)\n",
    "df_result_shuff_sems = pd.DataFrame([], columns=colNames, index=my_index, dtype=float)\n",
    "for key in mTypeDats:\n",
    "    rodents = mTypeDats[key]\n",
    "    for day, mice in rodents:\n",
    "        for m in mice:\n",
    "            df_result_means.loc[(key, day, m),:] = df_results.loc[key, day, :].mean()\n",
    "            df_result_sems.loc[(key, day, m),:] = np.sum([df_results.loc[key, day, x, :].sem()**2 for x in mTypes[key] if not df_results.loc[key, day, x, :].empty], axis=0)**0.5\n",
    "            \n",
    "            df_result_shuff_means.loc[(key, day, m),:] = df_results_shuff.loc[key, day, :].mean()\n",
    "            df_result_shuff_sems.loc[(key, day, m),:] = np.sum([df_results_shuff.loc[key, day, x, :].sem()**2 for x in mTypes[key] if not df_results_shuff.loc[key, day, x, :].empty], axis=0)**0.5\n",
    "        \n",
    "df_result_sems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_means.to_csv('[3PC][per-rodent]sucrose-alp-shuff-mean.csv')\n",
    "df_result_sems.to_csv('[3PC][per-rodent]sucrose-alp-shuff-sem.csv')\n",
    "df_result_shuff_means.to_csv('[3PC][per-rodent]sucrose-shuff-shuff-mean.csv')\n",
    "df_result_shuff_sems.to_csv('[3PC][per-rodent]sucrose-shuff-shuff-sem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in mTypeDats:\n",
    "    rodents = mTypeDats[key]\n",
    "    for day, mice in rodents:\n",
    "        for m in mice:\n",
    "            plt.plot(df_results.loc[key, day, m,:].mean(), label=\"ALP v Shuff\")\n",
    "            plt.plot(df_results_shuff.loc[key, day, :].mean(), label=\"Shuff v Shuff\")\n",
    "            plt.title(m + \" \" + key + \" \" + day)      \n",
    "            plt.ylim((0.375, 0.775))  \n",
    "            plt.xticks(rotation=90)\n",
    "            plt.legend() \n",
    "            plt.show()\n",
    "            # plt.savefig(f\"[-10,10][PCA-full][meanPCA][centerTimeNorm]ALPvBL\\\\\"+m, bbox_inches='tight')\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allenviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3af0ca5169093b1f722c85174fa04ebcbb3ecd77a354985cf25191ea0cf5f77e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
